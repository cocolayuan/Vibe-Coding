问题编号,Sabrina（受访者1）,受访者2,受访者3,受访者4,受访者5,,,,,,,,,,,,,
总结,"1. 生成节点放置位置困惑：首次使用时不清楚生成节点是否必须紧跟交互节点之后，还是只需在生成视频前设置即可

2. 分支判断也需等候视频：之前未预料到分支判断节点也需要准备超时等候视频，后来临时补加

3. 首次使用时不清楚分支节点需上传内容：奥特曼项目中才发现分支判断可以实现不同结局走向

4. 模型差异导致画面不一致：自有工作流使用的模型与 ROTO 使用的 Veo 模型不同，导致文生视频画面风格可能跳跃

5. 撤回功能缺失（已上线）/ 实时保存不灵敏：误触删掉已填满内容的节点，退出后内容丢失

6. 内置语言模型润色需求：希望在写剧情背景和提示词时可直接调用语言模型，比跳转其他 AI 平台更方便",,,,,,,,,,,,,,,,,
核心发现,"1.学习曲线集中在首次使用：用过一次所有节点后即可掌握，说明产品逻辑本身可学习性强

2.「剧情背景」和「提示词」填写是最大痛点：不确定 AI 理解能力如何，需要参考案例才能上手，包括 @引用方式也不清楚

3.等待时间长（~80秒）是体验关键挑战：需要从脚本层面就开始设计等待片段

4. 交互深度与制作成本强关联：观众参与度越高，分支越多，制作难度和成本相应增长",,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,
"个人
创作经验","1. 提示词复用策略：直接拿内容组工作流里生视频的提示词，加固定限定（如亚洲人、胶片感、都市文艺片等），Veo 生成控制画面风格一致性会好一些

2. 超时等候视频设计：一般用空镜或氛围感画面，保证观感不重复、不突兀，剧情不做明显推进。「叠加AI」超时等候约80秒，分支判断超时等候约10秒，能清晰区分

3. 生成模型：首帧 vs 文生视频选择策略：
- 文生：用户回答五花八门、无法用统一画面开始时（🌰「最后的观众」——问""你觉得爱是怎么样的？""，无法固定场景）
- 首帧固定：有清晰场景设定时（🌰「奥特曼」——有设定好的结局场景）",,,,,,,,,,,,,,,,,